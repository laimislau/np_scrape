{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m_pydevd_frame_eval/pydevd_frame_evaluator.pyx:256\u001b[0m, in \u001b[0;36m_pydevd_frame_eval.pydevd_frame_evaluator.get_func_code_info\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\Users\\\\laimis\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.10.6\\\\lib\\\\site-packages\\\\requests\\\\sessions.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:867\u001b[0m, in \u001b[0;36mget_abs_path_real_path_and_base_from_frame\u001b[1;34m(frame, NORM_PATHS_AND_BASE_CONTAINER)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m NORM_PATHS_AND_BASE_CONTAINER[frame\u001b[39m.\u001b[39;49mf_code\u001b[39m.\u001b[39;49mco_filename]\n\u001b[0;32m    868\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# This one is just internal (so, does not need any kind of client-server translation)\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\Users\\\\laimis\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.10.6\\\\lib\\\\site-packages\\\\requests\\\\sessions.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:831\u001b[0m, in \u001b[0;36mget_abs_path_real_path_and_base_from_file\u001b[1;34m(filename, NORM_PATHS_AND_BASE_CONTAINER)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 831\u001b[0m     \u001b[39mreturn\u001b[39;00m NORM_PATHS_AND_BASE_CONTAINER[filename]\n\u001b[0;32m    832\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\Users\\\\laimis\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.10.6\\\\lib\\\\site-packages\\\\requests\\\\sessions.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:385\u001b[0m, in \u001b[0;36m_abs_and_canonical_path\u001b[1;34m(filename, NORM_PATHS_CONTAINER)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m NORM_PATHS_CONTAINER[filename]\n\u001b[0;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\Users\\\\laimis\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.10.6\\\\lib\\\\site-packages\\\\requests\\\\sessions.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m_pydevd_frame_eval/pydevd_frame_evaluator.pyx:258\u001b[0m, in \u001b[0;36m_pydevd_frame_eval.pydevd_frame_evaluator.get_func_code_info\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:885\u001b[0m, in \u001b[0;36mget_abs_path_real_path_and_base_from_frame\u001b[1;34m(frame, NORM_PATHS_AND_BASE_CONTAINER)\u001b[0m\n\u001b[0;32m    882\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(f\u001b[39m.\u001b[39mrfind(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m), f\u001b[39m.\u001b[39mrfind(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m))\n\u001b[0;32m    883\u001b[0m     \u001b[39mreturn\u001b[39;00m f, f, f[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 885\u001b[0m ret \u001b[39m=\u001b[39m get_abs_path_real_path_and_base_from_file(f)\n\u001b[0;32m    886\u001b[0m \u001b[39m# Also cache based on the frame.f_code.co_filename (if we had it inside build/bdist it can make a difference).\u001b[39;00m\n\u001b[0;32m    887\u001b[0m NORM_PATHS_AND_BASE_CONTAINER[frame\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_filename] \u001b[39m=\u001b[39m ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:852\u001b[0m, in \u001b[0;36mget_abs_path_real_path_and_base_from_file\u001b[1;34m(filename, NORM_PATHS_AND_BASE_CONTAINER)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[39melif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m$py.class\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    850\u001b[0m         f \u001b[39m=\u001b[39m f[:\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m$py.class\u001b[39m\u001b[39m'\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 852\u001b[0m abs_path, canonical_normalized_filename \u001b[39m=\u001b[39m _abs_and_canonical_path(f)\n\u001b[0;32m    854\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     base \u001b[39m=\u001b[39m os_path_basename(canonical_normalized_filename)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:411\u001b[0m, in \u001b[0;36m_abs_and_canonical_path\u001b[1;34m(filename, NORM_PATHS_CONTAINER)\u001b[0m\n\u001b[0;32m    408\u001b[0m abs_path \u001b[39m=\u001b[39m _apply_func_and_normalize_case(filename, os_path_abspath, isabs, normalize)\n\u001b[0;32m    410\u001b[0m normalize \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m real_path \u001b[39m=\u001b[39m _apply_func_and_normalize_case(filename, os_path_real_path, isabs, normalize)\n\u001b[0;32m    413\u001b[0m \u001b[39m# cache it for fast access later\u001b[39;00m\n\u001b[0;32m    414\u001b[0m NORM_PATHS_CONTAINER[filename] \u001b[39m=\u001b[39m abs_path, real_path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py:438\u001b[0m, in \u001b[0;36m_apply_func_and_normalize_case\u001b[1;34m(filename, func, isabs, normalize_case, os_path_exists, join)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    434\u001b[0m     \u001b[39m# Not really a file, rather a synthetic name like <string> or <ipython-...>;\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     \u001b[39m# shouldn't be normalized.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m filename\n\u001b[1;32m--> 438\u001b[0m r \u001b[39m=\u001b[39m func(filename)\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isabs:\n\u001b[0;32m    441\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os_path_exists(r):\n",
      "File \u001b[1;32mc:\\Users\\laimis\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\ntpath.py:705\u001b[0m, in \u001b[0;36mrealpath\u001b[1;34m(path, strict)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39m# Ensure that the non-prefixed path resolves to the same path\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mif\u001b[39;00m _getfinalpathname(spath) \u001b[39m==\u001b[39m path:\n\u001b[0;32m    706\u001b[0m         path \u001b[39m=\u001b[39m spath\n\u001b[0;32m    707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    708\u001b[0m     \u001b[39m# If the path does not exist and originally did not exist, then\u001b[39;00m\n\u001b[0;32m    709\u001b[0m     \u001b[39m# strip the prefix anyway.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: '_pydevd_frame_eval.pydevd_frame_evaluator.get_bytecode_while_frame_eval_39'\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_frame_eval/pydevd_frame_evaluator.pyx\", line 258, in _pydevd_frame_eval.pydevd_frame_evaluator.get_func_code_info\n",
      "  File \"C:\\Users\\laimis\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py\", line 885, in get_abs_path_real_path_and_base_from_frame\n",
      "    ret = get_abs_path_real_path_and_base_from_file(f)\n",
      "  File \"C:\\Users\\laimis\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py\", line 852, in get_abs_path_real_path_and_base_from_file\n",
      "    abs_path, canonical_normalized_filename = _abs_and_canonical_path(f)\n",
      "  File \"C:\\Users\\laimis\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py\", line 411, in _abs_and_canonical_path\n",
      "    real_path = _apply_func_and_normalize_case(filename, os_path_real_path, isabs, normalize)\n",
      "  File \"C:\\Users\\laimis\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py\", line 438, in _apply_func_and_normalize_case\n",
      "    r = func(filename)\n",
      "  File \"c:\\Users\\laimis\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\ntpath.py\", line 705, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<function Session.__init__ at 0x00000242EBC4EA70> returned NULL without setting an exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m## Ingredientai\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m resp \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhttps://www.15min.lt/maistas/receptas/varskes-ir-fermentinio-surio-pyragas-8796\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(resp\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m all_ingredients: List[Dict] \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\laimis\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\laimis\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\requests\\api.py:58\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Constructs and sends a :class:`Request <Request>`.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39m:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m  <Response [200]>\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39;49mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mSystemError\u001b[0m: <function Session.__init__ at 0x00000242EBC4EA70> returned NULL without setting an exception"
     ]
    }
   ],
   "source": [
    "## Ingredientai\n",
    "resp = requests.get(\"https://www.15min.lt/maistas/receptas/varskes-ir-fermentinio-surio-pyragas-8796\")\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "all_ingredients: List[Dict] = []\n",
    "\n",
    "recipe_title = soup.find(\"div\", class_=\"recipe-head\").find(\"h1\").text.strip()\n",
    "recipe_image = soup.find(\"div\", class_=\"image\").find(\"img\").get(\"src\")\n",
    "recipe_ingredients = soup.find(\"ul\", class_=\"ingredients\").find_all(\"li\")\n",
    "for ingredient in recipe_ingredients:\n",
    "    the_ingredient = ingredient.find_all(\"span\")\n",
    "    all_ingredients.append({\n",
    "        \"ingredient_name\": the_ingredient[0].text.strip(),\n",
    "        \"ingredient_amount\": the_ingredient[2].text.strip(),\n",
    "        \"ingredient_note\": the_ingredient[3].text.strip()\n",
    "    })\n",
    "\n",
    "#all_ingredients\n",
    "\n",
    "## Paruosimo budas\n",
    "recipe_manual: List[str] = []\n",
    "recipe_making_steps = soup.find(\"div\", class_=\"description text\").find_all(\"p\")\n",
    "\n",
    "recipe_making_steps\n",
    "\n",
    "\n",
    "\n",
    "for step in recipe_making_steps:\n",
    "    stepsas = step.text.strip()\n",
    "    recipe_manual.append(stepsas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Info apie viena recepta\n",
    "\n",
    "def extract_recipe_ingredients(url: str) -> str:\n",
    "    ## Ingredientai\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    all_ingredients: List[Dict] = []\n",
    "\n",
    "    recipe_title = soup.find(\"div\", class_=\"recipe-head\").find(\"h1\").text.strip()\n",
    "    recipe_image = soup.find(\"div\", class_=\"image\").find(\"img\").get(\"src\")\n",
    "    recipe_ingredients = soup.find(\"ul\", class_=\"ingredients\").find_all(\"li\")\n",
    "    for ingredient in recipe_ingredients:\n",
    "        ingredient_span = ingredient.find_all(\"span\")\n",
    "        all_ingredients.append({            \n",
    "                \"ingredient_name\": ingredient_span[0].text.strip(),\n",
    "                \"ingredient_amount\": ingredient_span[2].text.strip(),\n",
    "                \"ingredient_note\": ingredient_span[3].text.strip()\n",
    "            })\n",
    "       \n",
    "    return str(all_ingredients)\n",
    "\n",
    "\n",
    "def extract_making_steps(url: str) -> str:\n",
    "\n",
    "    ## Paruosimo budas\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    recipe_manual: List[str] = []\n",
    "    recipe_making_steps = soup.find(\"div\", class_=\"description text\").find_all(\"p\")\n",
    "\n",
    "    for step in recipe_making_steps:\n",
    "        step_to_txt = step.text.strip()\n",
    "        recipe_manual.append(step_to_txt)\n",
    "    \n",
    "    return \"\\n\".join(recipe_manual) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IKEA search products\n",
    "\n",
    "# sudeda paieskos rezultatos is pirmo psl\n",
    "\n",
    "def search_products(url) -> List[Dict]:\n",
    "    \"\"\"Function for doing search in ikea.lt\"\"\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    products: List[Dict] = []\n",
    "\n",
    "    search_results_all = soup.find_all(\"div\", class_=\"col-6 col-md-4 col-lg-3 p-0 itemBlock\")\n",
    "    for product in search_results_all:\n",
    "        link = product.find(\"div\", class_=\"itemInfo\").a.get(\"href\")\n",
    "        products.append({            \n",
    "                    \"product_name\": product.find(\"div\", class_=\"itemInfo\").a.text.strip(),\n",
    "                    \"product_info\": product.find(\"div\", class_=\"itemInfo\").find(\"div\", class_ = \"itemPrice-wrapper\").span.text.replace(\" €\", \"\"),\n",
    "                    \"product_link\": f\"https://www.ikea.lt{link}\",\n",
    "                    \"product_image\": product.find(\"div\", class_ = \"productImg\").img.get(\"src\")\n",
    "                })\n",
    "\n",
    "    return products\n",
    "    \n",
    "#prod = search_products(\"https://www.ikea.lt/lt/search/?q=kede\")\n",
    "#prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IKEA retrieve links\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "__items_per_page__: int = 40\n",
    "__domain__: str = \"https://www.ikea.lt\"\n",
    "\n",
    "\n",
    "class Furniture(BaseModel):\n",
    "    \"\"\"Class for base properties of furniture\"\"\"\n",
    "    furniture_name: str\n",
    "    furniture_description: str\n",
    "    furniture_price = int\n",
    "    furniture_image_link: str\n",
    "    furniture_key_features: str\n",
    "    furniture_size: str\n",
    "    \n",
    "    #furniture_stock_in_store: int    \n",
    "class FurnitureLink(BaseModel):\n",
    "    url: str\n",
    "\n",
    "\n",
    "def _get_page_content(query: str) -> Optional[BeautifulSoup]:\n",
    "        \"\"\"Method to get needed content from search result page or whatever related page.\"\"\"\n",
    "        resp = requests.get(query)\n",
    "        if resp.status_code == 200:\n",
    "            return BeautifulSoup(resp.content)\n",
    "        raise Exception(\"Cannot get content. Site is unreachable.\")\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "\n",
    "def _retrieve_item_links2(results_count: int, keyword: str) -> List[FurnitureLink]: # prideti self\n",
    "    \"\"\"Method to search furnitures by keyword and save specifed number of results.\"\"\"\n",
    "    results: List[str] = []  #[FurnitureLink] = []        \n",
    "    pages_to_iterate: int = (results_count // __items_per_page__) + 1 # kiek paieskos rezultatu puslapiu naudoti        \n",
    "    \n",
    "    for page_num in range(1, pages_to_iterate + 1):\n",
    "        content = _get_page_content(f\"{__domain__}/lt/search/?q={keyword}&page={page_num}\") #pries metoda prideti self\n",
    "        pages_count = content.find(\"ul\", class_=\"pagination mb-0\")\n",
    "        no_results = content.find(\"div\", class_=\"col mt-4\")\n",
    "        \n",
    "        if pages_count != None:\n",
    "            max_number_of_pages = int(content.find(\"ul\", class_=\"pagination mb-0\").find_all(\"li\", class_=\"page-item\")[3].text)\n",
    "        elif no_results != None:           \n",
    "            max_number_of_pages = 0\n",
    "        else:\n",
    "            max_number_of_pages = 1\n",
    "        \n",
    "        if content:\n",
    "            if max_number_of_pages >= pages_to_iterate:                        \n",
    "                all_items_per_page = content.find_all(\"div\", class_=\"col-6 col-md-4 col-lg-3 p-0 itemBlock\")\n",
    "                counter = 1\n",
    "                \n",
    "                while results_count >= counter:                                                                    \n",
    "                    for item in all_items_per_page:\n",
    "                        link = item.find(\"div\", class_=\"itemInfo\").a.get(\"href\")\n",
    "                        item = f\"{__domain__}{link}\"\n",
    "                        results.append(item)  #(FurnitureLink(url = item))\n",
    "                        counter += 1                        \n",
    "                    \n",
    "            else: \n",
    "                print(f\"Search has less results than requested.\")\n",
    "                break\n",
    "        if not content:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def _retrieve_item_links(results_count: int, keyword: str) -> List[FurnitureLink]:\n",
    "        \"\"\"Method to search furnitures by keyword and save specifed number of results.\"\"\"\n",
    "        results: List[FurnitureLink] = []        \n",
    "        pages_to_iterate = (results_count // __items_per_page__) + 1 # kiek paieskos rezultatu puslapiu naudoti        \n",
    "        \n",
    "        for page_num in range(1, pages_to_iterate + 1):\n",
    "            content = _get_page_content(f\"{__domain__}/lt/search/?q={keyword}&page={page_num}\")\n",
    "            pages_count = content.find(\"ul\", class_=\"pagination mb-0\")\n",
    "            no_results = content.find(\"div\", class_=\"col mt-4\")\n",
    "            \n",
    "            if pages_count != None:\n",
    "                max_number_of_pages = int(content.find(\"ul\", class_=\"pagination mb-0\").find_all(\"li\", class_=\"page-item\")[3].text)\n",
    "            elif no_results != None:           \n",
    "                max_number_of_pages = 0\n",
    "            else:\n",
    "                max_number_of_pages = 1\n",
    "\n",
    "            if content:\n",
    "                if max_number_of_pages >= pages_to_iterate:                        \n",
    "                    all_items_per_page = content.find_all(\"div\", class_=\"col-6 col-md-4 col-lg-3 p-0 itemBlock\")\n",
    "                    counter = 1\n",
    "\n",
    "                    while results_count >= counter:                                                 \n",
    "                        for item in all_items_per_page:\n",
    "                            link = item.find(\"div\", class_=\"itemInfo\").a.get(\"href\")\n",
    "                            item = f\"{__domain__}{link}\"                                 \n",
    "                            results.append(FurnitureLink(url = item))\n",
    "                            counter += 1\n",
    "                else: \n",
    "                    print(f\"Search has less results than requested.\")\n",
    "                    break\n",
    "            if not content:\n",
    "                break\n",
    "\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[39m=\u001b[39m _retrieve_item_links(\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mledai\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m links \u001b[39m=\u001b[39m FurnitureLink(test)\n",
      "File \u001b[1;32mc:\\Users\\laimis\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\site-packages\\pydantic\\main.py:333\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes exactly 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "test = _retrieve_item_links(1, \"ledai\")\n",
    "links = FurnitureLink()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IKEA get key features\n",
    "\n",
    "def _extract_key_features(content: BeautifulSoup) -> str:  # pridet self\n",
    "    results: List[str] = []   \n",
    "    features = content.find(\"div\", class_=\"tab-pane_box\").find_all(\"p\")\n",
    "    \n",
    "    for feature in features: \n",
    "        feature_line = feature.text.strip()\n",
    "        results.append(feature_line)       \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_furniture_size(content: BeautifulSoup) -> str: #pridet \n",
    "    results: List[str] = []\n",
    "    measures = content.find_all(\"div\", class_=\"tab-pane_box\")[1].find_all(\"tr\") #.find(\"table\")\n",
    "    \n",
    "    for measure in measures:\n",
    "        measure_line = measure.text.strip()\n",
    "        results.append(measure_line)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Furniture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m content \u001b[39m=\u001b[39m BeautifulSoup(resp\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m##############################\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_retrieve_furniture_info\u001b[39m(link: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Furniture]: \u001b[39m#prideti self, link: FurnitureLink prie attr\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[39m\"\"\"Method to get main info about furniture.\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         content \u001b[39m=\u001b[39m _get_page_content(link\u001b[39m.\u001b[39murl)  \u001b[39m# prideti self prie get metodo\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Furniture' is not defined"
     ]
    }
   ],
   "source": [
    "## IKEA extract main info\n",
    "#resp = requests.get(\"https://www.ikea.lt/lt/products/valgomasis/sedimieji-valgomojo-baldai/kedes-ir-suoliukai/terje-sulankstomoji-kede-sviesi-pilka-balta-art-80456982\")\n",
    "#resp = requests.get(\"https://www.ikea.lt/lt/products/ikea-verslui/nekilnojamasis-turtas/sofos/jattebo-dviviete-moduline-sofa-tamsi-geltona-zalia-spr-29471405\")\n",
    "resp = requests.get(\"https://www.ikea.lt/lt/products/miegamasis/sistema-pax/pakabai-kiti-drabuziu-avalynes-priedai/omtanksam-batu-saukstas-antracito-sp-art-70378070\")\n",
    "content = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "def _retrieve_furniture_info(link: str) -> Optional[Furniture]: #prideti self, link: FurnitureLink prie attr\n",
    "        \"\"\"Method to get main info about furniture.\"\"\"\n",
    "        content = _get_page_content(link.url)  # prideti self prie get metodo\n",
    "\n",
    "        if content:\n",
    "            try:\n",
    "                furniture_name = content.find(\"div\", class_=\"d-flex align-items-center flex-wrap\").h3.text\n",
    "                furniture_description = content.find(\"h4\", class_=\"itemFacts font-weight-normal\").span.text\n",
    "                furniture_price = int(content.find(\"div\", class_=\"itemPrice-wrapper\").p.span.text.replace(\" €\", \"\"))\n",
    "            except AttributeError:\n",
    "                return None\n",
    "\n",
    "            try:\n",
    "                furniture_image_link = content.find(\"a\", class_ = \"slideImg\").find(\"img\").get(\"src\")\n",
    "            except KeyError:\n",
    "                furniture_image_link = None\n",
    "\n",
    "            return Furniture(\n",
    "                furniture_name = furniture_name,\n",
    "                furniture_description = furniture_description,\n",
    "                furniture_price = furniture_price,\n",
    "                furniture_image_link = furniture_image_link,\n",
    "                furniture_key_features = _extract_key_features(content), # self\n",
    "                furniture_size = _extract_furniture_size(content), # self\n",
    "\n",
    "                #furniture_stock_in_store = int,                \n",
    "            )\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pabandyt su selenium, nes reikia hitint mygtuka\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def _check_number_in_stock(content: BeautifulSoup) -> str: # self\n",
    "    quantity = content.find(\"div\", class_=\"message noCursor d-flex\").find(\"p\").text\n",
    "    driver = webdriver.Chrome(options=options,chrome_options=chrome_options)\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.get(url)\n",
    "    #time.sleep(5)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laimis\\AppData\\Local\\Temp\\ipykernel_9112\\467024139.py:30: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(options=options,chrome_options=chrome_options)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'h1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m page_source \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n\u001b[0;32m     36\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(page_source, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m check \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39merror-content\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mh1\u001b[39m.\u001b[39mtext\n\u001b[0;32m     39\u001b[0m \u001b[39mprint\u001b[39m(check)\n\u001b[0;32m     43\u001b[0m \u001b[39m#driver.close()\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# nepamirst driver.close() or driver.quit()\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'h1'"
     ]
    }
   ],
   "source": [
    "## SELENIUM\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# pip install webdriver-manager\n",
    "from selenium.webdriver.chrome.service import Service # del netinkamos driverio versijos galima autoamtiskai sutvarkjyt\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "# run Selenium in the background by configuring webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.headless = True # hide GUI\n",
    "options.add_argument(\"start-maximized\") # open gui in a full screen mode\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable_automation\"])\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "\n",
    "# configure chrome browser to not load images and javascript\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    # this will disable image loading\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://www.nordpoolgroup.com/en/Market-data1/Dayahead/Area-Prices/LT/Hourly/?view=table\"\n",
    "driver = webdriver.Chrome(options=options,chrome_options=chrome_options)\n",
    "#driver.implicitly_wait(10)\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "page_source = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "check = soup.find(\"div\", id=\"error-content\").h1.text\n",
    "print(check)\n",
    "\n",
    "\n",
    "\n",
    "#driver.close()\n",
    "# nepamirst driver.close() or driver.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORDPOOL - METHODS TO GET PAGE CONTENT USING SELENIUM AND RETURN AS SOUP\n",
    "\n",
    "# Needs a proper method to sleep during execution\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# pip install webdriver-manager\n",
    "from selenium.webdriver.chrome.service import Service # del netinkamos driverio versijos galima autoamtiskai sutvarkjyt\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "country: str = \"LT\"\n",
    "query: str = f\"https://www.nordpoolgroup.com/en/Market-data1/Dayahead/Area-Prices/{country}/Hourly/?view=table\"\n",
    "\n",
    "\n",
    "def _get_page_content(query: str) -> Optional[BeautifulSoup]:\n",
    "        \"\"\"Method to get needed content from search result page or whatever related page.\"\"\"\n",
    "        \n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        # this will disable image loading\n",
    "        chrome_options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "        \n",
    "        driver = webdriver.Chrome(chrome_options=chrome_options)   #options=options,    \n",
    "        driver.get(query)\n",
    "        time.sleep(3)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        checker = soup.find(\"div\", id=\"error-content\")\n",
    "                \n",
    "        \n",
    "        if checker is None:            \n",
    "            return soup\n",
    "        elif checker.h1.text == \"Important information\":\n",
    "            print(\"Wrong input.\")\n",
    "            \n",
    "        driver.quit()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_get_page_content(query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sql_query = '''SELECT lt_id FROM nordpool.HourlyPricesLT where date_of_price=%s;''' %(today)\\n        cur.execute(sql_query)\\n        results = cur.fetchall()\\n        for result in results:\\n            year_id = int(result[0])\\n            return year_id\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MYSQL METHODS\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "def _push_to_database(mysql_query: str, params: tuple = None) -> None:\n",
    "    \"\"\"Methods retrieves year id from database. If nno such year in database returns NONE.\"\"\"\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "        user=os.environ.get(\"DB_USER\"),\n",
    "        password=os.environ.get(\"DB_PASSWORD\"),\n",
    "        database=os.environ.get(\"DATABASE\"),\n",
    "        port=int(os.environ.get(\"DB_PORT\")),\n",
    "        host=os.environ.get(\"DB_HOST\"),\n",
    "        auth_plugin=os.environ.get(\"AUTH_PLUGIN\")\n",
    "        ) \n",
    "\n",
    "        cur = conn.cursor(prepared=True)        \n",
    "        cur.execute(mysql_query, params)\n",
    "        conn.commit()\n",
    "        print(\"It seems that records inserted succesfully\")\n",
    "        \n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Failed to execute MySQL query {}\".format(error)) # VIETA LOGINIMUI\n",
    "\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "            print(\"MySQL conn is closed.\") #VIETA LOGINIMUI\n",
    "\n",
    "\n",
    "\n",
    "def _check_date_in_database(params: str) -> bool:\n",
    "    \"\"\"Method checks if date exists in database. Returns boolean.\"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "        user=os.environ.get(\"DB_USER\"),\n",
    "        password=os.environ.get(\"DB_PASSWORD\"),\n",
    "        database=os.environ.get(\"DATABASE\"),\n",
    "        port=int(os.environ.get(\"DB_PORT\")),\n",
    "        host=os.environ.get(\"DB_HOST\"),\n",
    "        auth_plugin=os.environ.get(\"AUTH_PLUGIN\")\n",
    "        ) \n",
    "\n",
    "        cur = conn.cursor(prepared=True)\n",
    "        mysql_query: str = \"\"\"SELECT date_of_price FROM nordpool.HourlyPricesLT where date_of_price=%s;\"\"\"\n",
    "        cur.execute(mysql_query, (params,))\n",
    "        cur.fetchone()\n",
    "        row_count = cur.rowcount\n",
    "        if row_count > 0:       \n",
    "            return True\n",
    "        return False  \n",
    "        \n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Failed to execute MySQL query {}\".format(error)) # VIETA LOGINIMUI\n",
    "\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "            print(\"MySQL conn is closed.\") #VIETA LOGINIMUI\n",
    "\n",
    "\n",
    "def _testas(sql_query: str, params: tuple) -> tuple:\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "        user=os.environ.get(\"DB_USER\"),\n",
    "        password=os.environ.get(\"DB_PASSWORD\"),\n",
    "        database=os.environ.get(\"DATABASE\"),\n",
    "        port=int(os.environ.get(\"DB_PORT\")),\n",
    "        host=os.environ.get(\"DB_HOST\"),\n",
    "        auth_plugin=os.environ.get(\"AUTH_PLUGIN\")\n",
    "        ) \n",
    "\n",
    "        cur = conn.cursor(prepared=True)\n",
    "        #cur.execute('''SELECT NOT EXISTS (SELECT * FROM nordpool.HourlyPricesLT where date_of_price=DATE('%s'));''' %(params))            \n",
    "        cur.execute(sql_query, params)\n",
    "        for i in cur:\n",
    "            return i\n",
    "               \n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Failed to execute MySQL query {}\".format(error)) # VIETA LOGINIMUI\n",
    "\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "            print(\"MySQL conn is closed.\") #VIETA LOGINIMUI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"sql_query = '''SELECT lt_id FROM nordpool.HourlyPricesLT where date_of_price=%s;''' %(today)\n",
    "        cur.execute(sql_query)\n",
    "        results = cur.fetchall()\n",
    "        for result in results:\n",
    "            year_id = int(result[0])\n",
    "            return year_id\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL conn is closed.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "data: str = \"2022-12-19\"\n",
    "check = _check_date_in_database(data)\n",
    "print(check)\n",
    "\n",
    "#print(testas)\n",
    "#print(type(testas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laimis\\AppData\\Local\\Temp\\ipykernel_9892\\17449903.py:28: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options)   #options=options,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL conn is closed.\n",
      "Date 2022-12-30 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2022-12-31 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2023-01-01 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2023-01-02 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2023-01-03 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2023-01-04 already in.\n",
      "MySQL conn is closed.\n",
      "Date 2023-01-05 already in.\n",
      "MySQL conn is closed.\n",
      "It seems that records inserted succesfully\n",
      "MySQL conn is closed.\n"
     ]
    }
   ],
   "source": [
    "## NORD POOL METHODS TO RETRIEVE DATA AND PUSH IT TO DB\n",
    "\n",
    "# pip install mysql-connector-python\n",
    "import os\n",
    "import mysql.connector\n",
    "from typing import List, Dict, Optional\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# pip install webdriver-manager\n",
    "from selenium.webdriver.chrome.service import Service # del netinkamos driverio versijos galima autoamtiskai sutvarkjyt\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime, date\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#poetry add python-dotenv - cia iadziant su jupiter\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def get_current_prices(soup = _get_page_content(query)) -> None:\n",
    "    \"\"\"Populate database with current data in main page.\"\"\"\n",
    "\n",
    "    dates = soup.find(\"tr\", class_=\"column-headers\").find_all(\"th\")\n",
    "    prices = soup.find(\"table\", id=\"datatable\").tbody.find_all(\"tr\")\n",
    "    counter: int = len(dates) # stulpeliu su datomis skaicius\n",
    "    \n",
    "    # Ripping dates off from the site     \n",
    "    for day_date in reversed(dates[1:counter]): \n",
    "        # Pakonvertuoja is 08-12-2022 i 2022-12-08 + pavercia i date tipa\n",
    "        date_object = datetime.strptime(day_date.text, '%d-%m-%Y').date()            \n",
    "        price_tags: List = [float]\n",
    "        exists: bool = _check_date_in_database(date_object)\n",
    "\n",
    "        if not exists:          \n",
    "            for priceline in prices[:24]:            \n",
    "                price_tag = float(priceline.find_all(\"td\")[counter - 1].text.replace(',', '.'))                      \n",
    "                price_tags.append(price_tag)\n",
    "                    \n",
    "            mysql_query: str = '''INSERT INTO nordpool.HourlyPricesLT (date_of_price, time_00_01, time_01_02, time_02_03, time_03_04, time_04_05, time_05_06, time_06_07, time_07_08, time_08_09, time_09_10, time_10_11, time_11_12, time_12_13, time_13_14, time_14_15, time_15_16, time_16_17, time_17_18, time_18_19, time_19_20, time_20_21, time_21_22, time_22_23, time_23_24)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'''\n",
    "            params: tuple = (date_object, price_tags[1], price_tags[2], price_tags[3], price_tags[4], price_tags[5], price_tags[6], price_tags[7], price_tags[8], price_tags[9], price_tags[10], price_tags[11], price_tags[12], price_tags[13], price_tags[14], price_tags[15], price_tags[16], price_tags[17], price_tags[18], price_tags[19], price_tags[20], price_tags[21], price_tags[22], price_tags[23], price_tags[24])\n",
    "            _push_to_database(mysql_query, params)\n",
    "            #counter -= 1\n",
    "        else:\n",
    "            #counter -= 1\n",
    "            print(f\"Date {date_object} already in.\") #loginimui\n",
    "        counter -= 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "test2 = get_current_prices()\n",
    "test2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dayy = \"07-12-2022\"\n",
    "date_object = datetime.strptime(dayy, '%d-%m-%Y').date()        \n",
    "\n",
    "day_id: int = date_object.day\n",
    "\n",
    "print(day_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd15ff02c2674030d92d029fb961e821d771c4cffa27b5d8a6cd677df156e173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
